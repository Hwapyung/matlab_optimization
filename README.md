Implementation of the various optimization methods in MATLAB:
- Gradient descent method 
- Momentum
- Adagrad
- RMSProp
- Adam

[See detail](http://ruder.io/optimizing-gradient-descent)

The performance can be evaluated through some [test functions](https://en.wikipedia.org/wiki/Test_functions_for_optimization).
