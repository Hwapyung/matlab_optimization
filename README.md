Implementation of the various optimization methods in MATLAB; 'Gradient descent method', 'Momentum', 'Adagrad', 'RMSProp' and 'Adam'
See detail: http://ruder.io/optimizing-gradient-descent

The performance can be evaluated through some test functions from https://en.wikipedia.org/wiki/Test_functions_for_optimization
